{{ define "archi" }}
<!DOCTYPE html>
<html>
	{{ template "header" }}
	<body>
		{{ template "topbar" }}
	<h2>Détails sur le système</h2>
	<h3>Architecture général</h3>
	<p>
	Golang est un langage impératif avec un concept de struct, qui sont ne première approximation équivalent à des classes. 
	Les slices servent grosso modo de list, notation "[]" et reposent sur des array.
	Une autre structure importante est les channel utilisé pour le travail en concurrence car go est inspiré par "Hoare's Communicating Sequential Processes".
	<p>
	</p>
	Mon au programme utilise une struct "Search" (dans le fichier "search.go") comme structure de base contenant l'information sur un corpus.
	L'index est sous la forme d'un arbre de préfixe (struct "Node" et "Root" dans trie.go).
	Chaque node contient une slice de ses fils et une slice de préfixes associé.
	De plus les nodes correspondants à un mon ont une slice de "Ref" une ref étant la combinaison d'une docID et d'un tableaux de poids utilisé pour les recherches vectorielle.
	De plus "search" contient des métadatas telles que le nombre de Token par documents ou la liste des titres.
	<p>
	</p>
	L'index est peuplé par des méthodes spécifique à CACM et CS276 décrites ci-dessous.
	<p>

	<h3>Requète boolénne</h3>
	<p>
	Tous le code nécessaire au requète booléenne est dans le fichier "bool_query.go".
	Le parsing des requètes est assez basique en comptant comme séparateur tout ce qui n'est ni une lettre ni un chiffre.
	Ensuite un AST est construit en interprétant les parenthèse, les AND, les OR et les NOT.
	L'AST est construit grace à l'algorithme de <a href="https://en.wikipedia.org/wiki/Shunting-yard_algorithm">Shunting-Yardh</a>.
	Un opérateur AND est inseré par défaut entre deux mot consécutifs sans opérateur définis.
	La requète échoue silencieusement si l'ensemble demandé est trop gros (requète composé uniquement d'un NOT par exemple), le résultats sera l'ensemble vide.
	</p>

	<h3>Requète vectorielle</h3>
	<p>
	Pour les requètes vectorielle le est encore plus basique, vu qu'il n'y a pas d'opérateur.
	Chaque terme est recherché dans l'index puis les listes de Ref sont mergé en sommant les poids, la liste résultante est ordonné.
	La liste entière est ordonné et renvoyé alors que après elle est réduite, il y aurait des optimisations possible dans ce cas.
	Pour pouvoir comparer les performances facilement 3 poids sont stocké:
	</p>
	<ul>
		<li>la fréquence brute: nombre de fois ou le mot est présent dans le document</li>
		<li>la fréquence log normalisé: 1 + le log de la valeur précédente</li>
		<li>la normalisation par 0.5: 0.5 + 0.5 * la fréquence sur la fréquence max dans ce document</li>
	</ul>
	<p>
	Tout ces poids sont normalisé par l'inverse document frequency.
	D'après les résultats de qrels fourni avec CACM le dernier poids est le plus intéressant.
	Les détails des performances de ces poids sont dans <a href="/qrels">qrels</a> pour l'ensemble des query et <a href="/precall">precall</a> pour les graphes moyen et les valeurs de MAPS.
	</p>

	<h3>Indexation de CACM</h3>
	<p>
	La struct de base pour mes index et le documents qui contient des "index intermédiaire" lié à un document.
	Cette struct est définie dans "document.go".
	Les mots présent dans le document et nettoyé sont stocké sous la forme d'une liste ordonné, avec une liste équivalente pour les fréquences brutes (i.e la fréquence en position 43 correspond au lexeme en position 43).
	Un dictionnaire était plus lent, mais la liste ordonné n'est pas parfaite, en particulier l'insertio est lente et serait critique avec des documets plius long.
	La solution serait peur être une skip list, ou une hashmap avec un hash plus rapide.
	</p>
	<p>
	Ces index intermédiaire sont ajouté à l'index principale dès qu'un document est lu dans son entiereté.
	Le fichier "cacm.go" contient la struct qui réalise le parsing.
	Le fichier est lu séquentiellement et une variable mémorise dans quel type de block on se situe (title, summary ...).
	Dans un premier temps j'avis séparé le lexing et le parsing mais au vu de la simplicité de la structure de donné ça c'est averé pas nécessaire.
	Les métadata des documents indexé sont aussi envoyé par un channel pour être ajouté à la struct "search".
	Cette construction est surtout pour avoir la même interface que CS276.
	</p>

	<h3>Indexation de CS276</h3>
	<p>
	L'indexation de CS276 est faite en parrallèle utilisant des workers qui recoivent les documents à traiter par des channels.
	Une goroutine (équivalent en plus légers des threads) envoie sur un channel la liste des documents à traiter.
	Les documents sont parsé, ce qui est très basique vu que le travail est quasiment déjà fait.
	Les index sont ajouté à l'arbre des préfixes ce qui est faisable de façon concurentiel car chaque node est protégé par un mutex (lock).
	Tous ces workers renvoient aussi les métadata au "thread" principale.
	Enfin un dernier thread de synchronisation fermera le channel des métadata quand tous l'index est parsé.
	</p>
	<img src="/archi_indexing.svg" style="margin:auto;width:100%"
	alt="archi indexing CS276">

	<h3>Commentaire sur l'index</h3>
	<p>
	L'index est un arbre des préfixes c'est une structure qui est très addapté au index de moteur de recherche.
	En effet contrairement à une structure de type hashmap la localité des donné est optimisé ce qui peut accelérer les requète.
	<p>
	L'insertion est faite en descendant l'arbre tant que c'est possible (le mutex autorise la lecture par plusieurs threads).
	Si nécessaire le radical est splitté: pour insérer "chat" dans un arbre avec le radical "chien", on introduit une node "ch" avec deux fils "at" et "ien".
	Enfin si une node terminal est atteinte la reférence (docId et poids) est ajouté à la liste de cet node.
	Cas deux dernières opérations utilisent le mutex pour bloquer l'écriture, et sont donc monothread.
	</p>
	<p>
	Un autre gros avantage est que sa structure ordonné permet un découpage du travail assez facilement.
	Propriété dont je profite en accèdant aux différentes nodes de façon concurentiel, vu que des modifications à un sous arbre n'impacte pas le reste de l'arbre.
	Cela permet d'autre chose dont je n'ai pas eu le temps de profiter pour faire un moteur de recherche qui serait vraiment distribué.
	Par exemple pour merger deux index le travail peut directement se découper en travail au niveau des fils de la racine (ou à une échelle plus basse récursivement).
	Pour ne pas avoir tous en mémoire ce qui serait nécessaire pour des corpus plus gros les nodes pourrait être soit sur fichier soit en mémoire est chargé uniquement quand elles sont lus.
	</p>

	<h3>Serialisation</h3>
	<p>
	Même si ce moteur triche un peu et garde son index en mémoire il est aussi sérialisé, ne serait-ce que pour ne pas avoir à le reconstruire à chaque fois.
	Le librairie utilisé pour encodes les différents fichier est gob qui fait partie de la librairie standart.
	Cependant l'arbre des préfixe est sérialisé à la main, la librairie devant lire le type de chaque struct, elle est très lente pour une structure récursive comme un arbre. 
	J'ai pu gagner 4 secondes sur le temps de sérialisation ainsi alors que mon code est peu optimisé.
	Cette sérialisation est détaillé dans "encoder.go".
	J'utilise du delta encoding et du Variable Byte Encoding pour les listes d'entier.
	Il y aurait probablement des optimisation à faire au niveau des listes de string, certaines étant des longues liste de la forme ['a', 'b', ...] et quasiment complète.
	</p>
	</body>
</html>
{{ end }}
