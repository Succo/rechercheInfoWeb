{{ define "archi" }}
<!DOCTYPE html>
<html>
	{{ template "header" }}
	<body>
		{{ template "topbar" }}
	<h2>Détails sur le système</h2>
	<h3>Architecture général</h3>
	<p>
	Golang est un langage impératif avec un concept de struct, qui sont ne première approximation équivalent à des classes. 
	Les slices servent grosso modo de list, notation "[]" et reposent sur des array.
	Une autre structure importante est les channel utilisé pour le travail en concurrence car go est inspiré par "Hoare's Communicating Sequential Processes".
	<p>
	</p>
	Mon au programme utilise une struct "Search" (dans le fichier "search.go") comme structure de base contenant l'information sur un corpus.
	L'index est sous la forme d'un arbre de préfixe (struct "Node" et "Root" dans trie.go).
	Chaque node contient une slice de ses fils et une slice de préfixes associé.
	De plus les nodes correspondants à un mon ont une slice de "Ref" une ref étant la combinaison d'une docID et d'un tableaux de poids utilisé pour les recherches vectorielle.
	De plus "search" contient des métadatas telles que le nombre de Token par documents ou la liste des titres.
	<p>
	</p>
	L'index est peuplé par des méthodes spécifique à CACM et CS276 décrites ci-dessous.
	<p>
	</p>
	Les requètes sont effectué par les struct "vector_query" et "bool_query" situé dans les fichiers respectif. 
	Le parsing des requètes est assez basique en comptant comme séparateur tout ce qui n'est ni une lettre ni un chiffre.
	Les requètes booléenne contruisent un AST à partir de la requète en appliquant l'algorithme de Shunting-yard des opérateur AND sont inseré par défauts entre deux mots consécutifs.
	Elles échoueront silencieusement si l'ensemble demandé est trop gros (requète composé uniquement d'un NOT par exemple).
	Pour les requètes vectorielle l'implémentation est encore plsu basique, chaque est recherché dans l'index puis les listes de Ref sont mergé en sommant les poids, la liste résultante est ordonné.
	Pour pouvoir comparer facilement 3 poids sont stocké:
	</p>
	<ul>
		<li>la fréquence brute: nombre de fois ou le mot est présent dans le document</li>
		<li>la fréquence log normalisé: 1 + le log de la valeur précédente</li>
		<li>la normalisation par 0.5: 0.5 + 0.5 * la fréquence sur la fréquence max dans ce document</li>
	</ul>
	<p>
	Tout ces poids sont normalisé par l'inverse document frequency.
	D'après les résultats de qrels fourni avec CACM le dernier poids est le plus intéressant.
	</p>

	<h3>Indexation de CACM</h3>
	<p>
	La struct de base pour mes index et le documents qui contient des "index intermédiaire" lié à un document.
	Cette struct est définie dans "document.go".
	Les mots présent dans le document et nettoyé sont stocké sous la forme d'une liste ordonné, avec une liste équivalene pour les fréquences brutes.
	Ces index intermédiaire sont ajouté à l'index principale dès qu'un document est lu dans son entiereté.
	Le fichier "cacm.go" contient la struct qui réalise le parsing.
	Le fichier est lu séquentiellement est une variable mémorise dans quel block on se situe.
	Les métadata des documents indexé sont aussi envoyé par un channel pour être ajouté à la struct "search".
	Cette construction est surtout pour avoir la même interface que CS276.
	</p>

	<h3>Indexation de CS276</h3>
	<p>
	L'indexation de CS276 est faite en parrallèle utilisant des workers qui recoivent les documents à traiter par des channels.
	Une goroutine (équivalent en plus légers des threads) envoie sur un channel la liste des documents à traiter.
	Les documents sont parsé ce qui est très basique vu que le travail est quasiment déjà fait.
	Les index sont ajouté à l'arbre des préfixes ce qui est faisable de façon concurentiel car chaque node est protégé par un mutex (lock).
	Tous ces workers renvoient aussi les métadata au "thread" principale.
	Enfin un dernier thread de synchronisation fermera le channel des métadata quand tous l'index est parsé.
	</p>
	<img src="/archi_indexing.svg" style="margin:auto;width:100%"
	alt="archi indexing CS276">

	<h3>Serialization</h3>
	<p>
	Même si ce moteur triche un peu et garde son index en mémoire il est aussi sérialisé, ne serait-ce que pour ne pas avoir à le reconstruire à chaque fois.
	Le librairie utilisé pour encodes les différents fichier est gob qui fait partie de la librairie standart.
	Cependant l'arbre des préfixe est sérialisé à la main, la librairie devant lire le type de chaque struct, elle est très lente pour une structure récursive comme un arbre. 
	J'ai pu gagner 4 secondes sur le temps de sérialisation ainsi alors que mon code est peu optimisé.
	Cette sérialisation est détaillé dans "encoder.go".
	J'utilise du delta encoding et du Variable Byte Encoding pour les listes d'entier.
	Il y aurait probablement des optimisation à faire au niveau des listes de string, certaines étant des longues liste de la forme ['a', 'b', ...] et quasiment complète.
	</p>
	</body>
</html>
{{ end }}
